{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Petition_W2V, D2V\n",
    "\n",
    "## 1. 국민청원 데이터\n",
    "\n",
    "### 1) 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 불러오기\n",
    "import csv\n",
    "\n",
    "contents = []\n",
    "labels = []\n",
    "\n",
    "with open('petition_sample.csv', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        #print(row)\n",
    "        if row: #그 줄에 내용이 있는 경우에만\n",
    "            contents.append(row[0]) #청원내용을 contents 리스트에 추가\n",
    "            labels.append(row[1]) #청원 category를 labels 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents size: 4000\n",
      "labels: {'미래', '일자리', '반려동물', '육아/교육'}\n",
      "document sample: 만일 하시는 대통령님 및 각 부처 장관님,주무관님들 안녕하세요!!\\n전남 목포에서 자영업을 하는 사람입니다.\\n국정운영을 너무 잘해주셔서  감사하다는 인사를 먼저드리겠습니다.\\n제가 청원 드리고자 하는 사안은 아래와 같습니다.\\n그 사안은 개성공단 관련 부분입니다.\\n이 사안은 오래전 개성공단이 폐쇄 되고, 그와 관련되어 문제들이 돌출되면서 한번씩 생각해봤습니다.\\n개성공단의 상징성은 제가 부연하지 않아도 아주 잘 아실거라 생각 하고 요점만 정리하여 말씀드리겠습니다.\\n저는 개성공단을 북측에 꼭 설치 해야되나 하는 의문이 계속 들었습니다.\\n북측과 인접한 강원도의 적합한 지역에 제2의 개성공단을  설치하면 안되나 하고 말이지요.\\n공단이 설치가 된다면, 강원지역의 경제활성화와 중소기업에 돌아가는 혜택, 북측에 공단이 위치했을때\\n지리적 불안전에서 오는 위험 해소, 제2의 개성공단이라는 남북화해의 상징성 등을 두루 갖추지 않을까 싶습니다.\\n또한 요즘 처럼 대북관계의 긴장감에서 오는 불안함이 제2의 개성공단 설치로 인하여 대화의 창구를 열어\\n관계를 계속 유지해간다면 긴장감이 어느 정도 해소 되지 않을까 싶습니다.\\n이상으로 부족한 글 읽어주셔서 감사합니다.\n"
     ]
    }
   ],
   "source": [
    "## 데이터 확인\n",
    "print('documents size:', len(contents))   #문서 수\n",
    "print('labels:', set(labels))   #카테고리 확인\n",
    "print('document sample:', contents[0])   #첫 번째 문서 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) train, test set 으로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(contents, labels, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) KoNLpy로 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## konlpy에서 Twitter 형태소 분석기를 import\n",
    "from konlpy.tag import Okt\n",
    "#from konlpy.tag import Twitter #konlpy에서 Twitter 형태소 분석기를 import\n",
    "\n",
    "twitter_tag = Okt()\n",
    "#twitter_tag = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 형태소에서 명사의 길이가 2 이상인 token만 추출하는 함수\n",
    "\n",
    "def tokenize(doc):\n",
    "    #return list(filter (lambda token: len(token) > 1, twitter_tag.morphs(doc)))\n",
    "    return list(filter (lambda token: len(token) > 1, twitter_tag.nouns(doc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['문재인', '대통령', '국정', '책임', '수고', '항상', '마음속', '응원', '지지', '저', '대기업', '통신사', '협력', '업체', '외주', '노동자', '우리', '문재인', '정부', '서민', '위', '사람', '먼저', '국정', '철학', '부합', '진정', '현실', '좀더', '면', '보고', '우선', '제', '생업', '일자리', '수입', '구조', '말씀', '저', '통신', '공사', '관련', '일', '외주', '노동자', '생활', '년', '가장', '아이', '명', '이일', '아이', '물런', '한번', '안정', '고정', '수입', '우리나라', '통신사', '대기업', '구조', '이', '협력', '업체', '지역구', '어서', '모든', '설치', '시공', '설비', '관련', '장일', '그', '영세', '협력', '업체', '대부분', '외주', '일용직', '노동자', '능직', '이', '의', '관점', '그', '일', '생업', '것', '고정', '여제', '대부분', '건', '얼마', '정액', '제', '수입', '불', '안정', '있을떄', '못']\n"
     ]
    }
   ],
   "source": [
    "## train data에서 명사만 100개 출력\n",
    "print(twitter_tag.nouns(X_train[1])[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['문재인', '대통령', '님', ',', '국정', '을', '책임', '지느라', '수고', '가', '많습니다', '항상', '마음속', '으로', '응원', '하고', '지지', '합니다', '\\\\', 'n', '저', '는', '대기업', '통신사', '들', '의', '협력', '업체', '에서', '일을하는', '외주', '노동자', '입니다', '\\\\', 'n', '우리', '문재인', '정부', '가', '서민', '을', '위', '하고', '사람', '이', '먼저', '이다', '라는', '국정', '철학', '에', '부합', '하고자', '한다면', '진정', '현실', '을', '\\\\', 'n', '좀더', '면', '면', '희', '들여다', '보고', '아셔야', '합니다', '안타깝습니다', '\\\\', 'n', '우선', ',', '제', '가', '생업', '으로', '하고있는', '일자리', '수입', '원', '구조', '부터', '말씀', '드리겠습니다', '\\\\', 'n', '저', '는', '통신', '공사', '관련', '일', '을', '하고', '있는', '외주', '노동자', '생활', '을', '근']\n"
     ]
    }
   ],
   "source": [
    "## train data에서 형태소 전부 포함해서 100개 출력\n",
    "print(twitter_tag.morphs(X_train[1])[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['문재인', '대통령', '국정', '책임', '수고', '항상', '마음속', '응원', '지지', '대기업', '통신사', '협력', '업체', '외주', '노동자', '우리', '문재인', '정부', '서민', '사람', '먼저', '국정', '철학', '부합', '진정', '현실', '좀더', '보고', '우선', '생업', '일자리', '수입', '구조', '말씀', '통신', '공사', '관련', '외주', '노동자', '생활', '가장', '아이', '이일', '아이', '물런', '한번', '안정', '고정', '수입', '우리나라', '통신사', '대기업', '구조', '협력', '업체', '지역구', '어서', '모든', '설치', '시공', '설비', '관련', '장일', '영세', '협력', '업체', '대부분', '외주', '일용직', '노동자', '능직', '관점', '생업', '고정', '여제', '대부분', '얼마', '정액', '수입', '안정', '있을떄', '실정', '그것', '이일', '종사', '사람', '전국', '적지', '그간', '대기업', '협력', '업체', '갑질', '둘째', '간다', '해도', '임금', '지급', '대기업', '먼저']\n"
     ]
    }
   ],
   "source": [
    "## tokenize 함수로 글자수 2 이상인 명사만 출력\n",
    "print(tokenize(X_train[1])[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train, test data tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = [tokenize(text) for text in X_train]\n",
    "test_texts = [tokenize(text) for text in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train text counts: 3000 , test text counts: 1000\n",
      "train text sample 문재인 대통령님, 국정을 책임 지느라 수고가 많습니다 항상 마음속으로 응원하고 지지합니다\\n저는 대기업 통신사들의 협력업체 에서 일을하는 외주 노동자 입니다\\n우리 문재인 정부가 서민을 위하고 사람이 먼저이다 라는 국정철학에  부합 하고자 한다면 진정 현실을\\n좀더 면면희 들여다 보고 아셔야 합니다  안타깝습니다\\n우선, 제가 생업으로 하고있는 일자리 수입원 구조부터 말씀 드리겠습니다\\n저는 통신공사 관련일을 하고 있는 외주 노동자 생활을 근 20여년 해오고 있는 가장 입니다\\n아이가 3명이고 이일을 해서 아이들을 키우고 있습니다\\n물런 단한번도 안정적 이고 고정적인 수입이 없었습니다  그러면 우리나라 통신사 대기업들의 구조를\\n보면 이들은 협력업체를 지역구에 두어서 모든 설치 시공 설비 관련 현장일을 시키고 있습니다\\n그 영세한 협력업체들은 대부분 외주 일용직 노동자 들을 (기능직 이죠) 저의관점 에서는\\n그 일을 생업으로 하는 것이 고정급여제가 아니고 대부분 한건당 얼마의 정액제 입니다\\n그러다 보니 수입은 불안정 하고 일이 있을떄는 하고 없으면 못하고 그런실정 입니다\\n그것까지 탓을 할수는 없다는것은 알고 있습니다\\n이일에 종사하는 사람들이 전국에 적지 않습니다,\\n그간 대기업들의 협력업체들 에게 갑질이니, 머니 그런것은 둘째로 치고 넘어 간다고 해도\\n임금 지급은 당연히 대기업 에서 먼저 물어야 하는데  온갇 이유를 들어 일을한지 월수로는 3개월 인데도\\n미비한것이 있다고 하여, 한푼도 지급하지 않고 있는 이런 행태를 과연\\n누가 진정 단한사람도 알고나 있는지요\\n대기업협력사 들은 고양이 목에 방울거는 형태라 말한마디도 못하고  그 영세한 협력업체들은\\n대기업들 에서 정산이 안되었다고 하며 돈을 지급하지 않고\\n그러면 그 노동자 들은 어떻겠습니까?\\n그런 오랜 악습이 수십년 동안 진행 되다가 지금은 다소 개선이 된줄알고 있는데 예전보다는 나아졌는데\\n이들 대기업들의 해묵은 악습은 또다시 명절을 앞두고 있는 지금 이시점에 벌어지고 있습니다\\n하물며 정부 발주공사를 대기업이 진행하는 지금\\n그런 공사를 진행하는것에 수많은 인력 자재 물품 기타등 용역이 소비대면서 벌어지는 것에  얼마나\\n담당부서자는 파학 이라도 하고 있는지 너무나 안타깝네요\\n대기업들 직원들 급여 한두달 지급 하지않는다면 난리가 나겠죠>??\\n그런데 우리 일용직 노동자 들은 한두달은 돈이 안나왔다 하면 그냥 끝입니다\\n가장 일선에서 가장 힘들고 열악한 조견 환경에서 힘든일을 하고 있는 현장 노동자 들의 처우개선은\\n바라지도 않습니다\\n다만 일한것에 대해서 최소한 전액은 지급 못하더라도 이들이 생활은 유지할수 있게금\\n어느정도 돈을 풀어 주어야 생활이되고 가족이 그돈으로 먹고살고\\n소비를하고, 그래야 하는것 아닌가요\\n대기업 에서는 정부발주 사업을 대신하여 하는 주사업자 이면 자신들이 먼저 자재비 임금등을 지급 하면서\\n진행하는 것이 상식 아닙니까?\\n그런데 요건이나 구비서류등을 미비한것이 있다는 온갇 이유를 들어 한푼도 지급하지 않으니\\n영세한 협력업체들은 자재비 경비 노무비 급여등을 한두달 어떻게 감당 하나요?\\n단순하게 물품구입 이라면 덜하겠지만 정부에서 시설공사를 통한  설비 장비 설치 공사를 통한 일이면\\n그에 수반되는 여러가지 구매대금 용역 인건비 경비 등에 대한것과 그것에 종사하는 노동자들의 임금도\\n최소한 어떻게 지급이 되고 있는지 관심이라도 표현 해주면\\n이런 대기업들이 이따위로 하겠습니까?\\n대기업 자신들은 혁신이니 원가절감이니 하면서 그 협력업체들은 몇번을 가고 또가고 반복을 해서 마쳐야 하는\\n상황을 만들어 놓고 자신들의 비용이 나가는 것이 아니기에 강요와 닥달만 하지\\n이들을 도와주어 어떻게 하면 협력사와 종사자들 에게 도움을 줄수있을까 고민하는\\n대기업 담당자 들은 단한명도 없습니다\\n최소한 정부예산 으로 정부 발주사업 이면. 이런 대기업 들의 횡포는 견제하고 감독을 할수있어야 하는것\\n아닙니까,.?  우리 노동자 들이 생존문재 임금에 대해서 관심을 가져 주시기를 간곡희 부탁드립니다\\n이런 악습의 관행이 어디 통신사 들 뿐입니까?\\n열이면 열 백이면 그중 거의 대부분 이런 악습의 관행을 이어가고 있습니다, 다른 업종도\\n그러면 그 종사자들의 수입은 불안정 하고 수입이 없으니 소비는 당연희 없고 그래도 일은 해야겠으니\\n속티 터지고 부당하고 억울해도 속을 태워 가면서 위험하고 힘든일을 해오던 일이라\\n참아내며 하고 있습니다,\\n다음주면 추석 명절 입니다,. 환경부 에서 발주한  공사를 하는 대기업 협력업체 에서 일하는 사람으로서\\n환경부가 대기업 에게 공사비를 지급 안하면 대기업이 사업원청 이니\\n대기업 에서 추석명절을 앞두고 있는데도 전혀 지급을 하지 않는다고 하면 외 환경부는\\n대기업들만 이런 공사를 선정 합니까, 이런 문재포함 해서 사업을 할수있는 역량이 되니 맡긴것 아닌가요,.\\n너무나 부당하고 속상 합니다 협력업체 들에게는 원성을 내고 큰소리를 내보아도 대기업 들이\\n결재를 하지않고 있어서 자기들도 가진돈을 다풀어서 돈이없다,\\n그런데도 그  대기업들은 추석명절에는 직원들 에게는 급여와 보너서 선물꾸러미는 주겠죠.\\n공사비는 이익은 대기업이 다 빼먹고  힘들고 어려운 일을 하는 협력업체들은 그 부스러기 주워 먹으려\\n끽소리도 못하고 그곳에 종사해서 생업을 이어가는 노동자 들은 누구를 원망하고 한탄 해야 합니까,.\\n정말 담당 공무원의 무능과 관심부족을 질타 할수밖에 없습니다,\\n하여, 바라건데 환경부 가 주관하고 있는 전기 자동차 사업관련 싸이클을 한번 점검 해주시고\\n그에 종사하는 여러가지 업체 자재 장비 공사업 노동자 이들의 처우개선을 바라지도 않습니다\\n다면  이들이 일한것에 대해서는 매달 일한만큼은 임금이 지급 될수 있도록 제도나 환경을 개선 해주기를\\n부탁 드립니다,\\n외냐, 최소한 민자공사도 아니고 정부 부처 발주공사 이면,  최소한 그에 수반대는 것에 자재 장비 임금등에\\n대해서는 그사업자가 책임을 질수있는 업체를 선정하고 그에 책임을 확인하는 이행하는것을 감독하는\\n공무원이 있다면 얼마나 많은 사람들이  편해 지겠습니까\\n이런 일들이 비일비재 하겠지만, 어떤 정부도 어느 공무원도 누구도 관심조차 없는 이런 행태를 파학하고\\n조금 이라도 개선의 여지가 있는지 관심을 가져 주시고 고쳐 주시면\\n사람이 먼저이다, 국정철학에 매우 진정 더 따뜻한 더운 가슴으로 문재인 정부가 온전하게 다가 오리라 믿습니다\\n제발 바라건데 노동자 들의 임금문재는 민자공사든 관급 공사든 어떤 식으로든 정부가 강력하게 선도하여\\n이런 오래된 악습과 폐해를 지금 이라도 조사를 하고 수정을 하여\\n사람이 먼저이다 라는 문재인 정부 철학에 부합되게 관심을 가져 주시고 감독을 부탁 드립니다\\n마지막으로 환경부 는 지금 발주한 공사에 대해서는  수급 사업자 에게는 그에 종사하는 노동자 들의\\n임금을 지급될수 있게 관리 감독을 해주시기를 간곡희 바랍니다,\n",
      "tokenized result ['문재인', '대통령', '국정', '책임', '수고', '항상', '마음속', '응원', '지지', '대기업', '통신사', '협력', '업체', '외주', '노동자', '우리', '문재인', '정부', '서민', '사람', '먼저', '국정', '철학', '부합', '진정', '현실', '좀더', '보고', '우선', '생업', '일자리', '수입', '구조', '말씀', '통신', '공사', '관련', '외주', '노동자', '생활', '가장', '아이', '이일', '아이', '물런', '한번', '안정', '고정', '수입', '우리나라', '통신사', '대기업', '구조', '협력', '업체', '지역구', '어서', '모든', '설치', '시공', '설비', '관련', '장일', '영세', '협력', '업체', '대부분', '외주', '일용직', '노동자', '능직', '관점', '생업', '고정', '여제', '대부분', '얼마', '정액', '수입', '안정', '있을떄', '실정', '그것', '이일', '종사', '사람', '전국', '적지', '그간', '대기업', '협력', '업체', '갑질', '둘째', '간다', '해도', '임금', '지급', '대기업', '먼저', '물어', '온갇', '이유', '한지', '수로', '개월', '지급', '행태', '과연', '누가', '진정', '사람', '대기업', '협력', '고양이', '방울', '형태', '한마디', '영세', '협력', '업체', '대기업', '정산', '지급', '노동자', '악습', '십년', '동안', '진행', '지금', '다소', '개선', '예전', '대기업', '해묵', '악습', '명절', '지금', '시점', '하물며', '정부', '발주', '공사', '대기업', '진행', '지금', '공사', '진행', '인력', '자재', '물품', '기타', '용역', '소비', '대면', '얼마나', '담당', '부서', '파학', '대기업', '직원', '급여', '지급', '난리', '우리', '일용직', '노동자', '그냥', '가장', '일선', '가장', '조견', '환경', '현장', '노동자', '처우', '개선', '바라지', '다만', '대해', '최소한', '전액', '지급', '생활', '유지', '정도', '주어', '생활', '가족', '소비', '래야', '대기업', '정부', '발주', '사업', '대신', '사업자', '이면', '자신', '먼저', '자재', '임금', '지급', '진행', '상식', '요건', '구비', '서류', '온갇', '이유', '지급', '영세', '협력', '업체', '자재', '경비', '노무', '급여', '감당', '하나요', '물품', '구입', '라면', '정부', '시설', '공사', '통한', '설비', '장비', '설치', '공사', '통한', '일이', '수반', '여러가지', '구매', '대금', '용역', '인건비', '경비', '그것', '종사', '노동자', '임금', '최소한', '지급', '관심', '표현', '대기업', '대기업', '자신', '혁신', '원가', '절감', '협력', '업체', '몇번', '반복', '상황', '자신', '비용', '강요', '닥달', '협력', '사자', '도움', '고민', '대기업', '담당자', '명도', '최소한', '정부', '예산', '정부', '발주', '사업', '이면', '대기업', '횡포', '견제', '감독', '우리', '노동자', '생존', '임금', '대해', '관심', '시기', '간곡', '악습', '관행', '어디', '통신사', '이면', '백이', '거의', '대부분', '악습', '관행', '어가', '다른', '업종', '사자', '수입', '안정', '수입', '소비', '연희', '가면', '일이', '다음주', '추석', '명절', '환경부', '발주', '공사', '대기업', '협력', '업체', '사람', '환경부', '대기업', '사비', '지급', '대기업', '사업', '대기업', '추석', '명절', '전혀', '지급', '환경부', '대기업', '공사', '선정', '포함', '사업', '역량', '협력', '업체', '원성', '큰소리', '보아', '대기업', '결재', '자기', '대기업', '추석', '명절', '직원', '급여', '보너', '선물', '꾸러미', '사비', '이익', '대기업', '협력', '업체', '부스러기', '끽소리', '종사', '생업', '어가', '노동자', '누구', '한탄', '정말', '담당', '공무원', '무능', '관심', '부족', '질타', '환경부', '주관', '전기', '자동차', '사업', '관련', '싸이클', '한번', '점검', '해주시', '종사', '여러가지', '업체', '자재', '장비', '사업', '노동자', '처우', '개선', '바라지', '대해', '매달', '만큼', '임금', '지급', '제도', '환경', '개선', '부탁', '최소한', '공사', '정부', '부처', '발주', '공사', '이면', '최소한', '반대', '자재', '장비', '임금', '대해', '사업자', '책임', '업체', '선정', '책임', '확인', '이행', '감독', '공무원', '얼마나', '사람', '비일비재', '정부', '공무원', '누구', '관심', '행태', '파학', '조금', '개선', '여지', '관심', '주시', '주시', '사람', '먼저', '국정', '철학', '매우', '진정', '가슴', '문재인', '정부', '온전', '다가', '오리', '제발', '노동자', '임금', '재는', '공사', '공사', '정부', '선도', '악습', '폐해', '지금', '조사', '수정', '사람', '먼저', '문재인', '정부', '철학', '부합', '관심', '주시', '감독', '부탁', '마지막', '환경부', '지금', '발주', '공사', '대해', '수급', '사업자', '종사', '노동자', '임금', '지급', '관리', '감독', '해주시', '간곡']\n",
      "test text sample 안녕하세요. 저희는 일학습병행제라는 제도를 하고 있는 20살 직장인 또는 대학생입니다. 저희는 고등학교에서 일학습병행제로 취업하여 2016년도에 시작해 2018년도에 완료하는 과정이였습니다. 그런데 갑작스럽게 바뀐 일학습병행제 법률로 인해 더이상 일학습병행제 제도를 실시할 수 없게 되었습니다.  한 업체에서 1년이상을 하지 못하여 폐지가 될 상황입니다. 당장 이번 11월 중순이 1년과정이 끝나는 시기인데 그 이후가 되면 완전히 저희는 강제적으로 일학습병행제를 끝낼 수 밖에 없습니다. 저희가 지금껏 쌓아올린 1년이란 시간을 허비하지 않도록 도와주세요. 어린 나이 고3 나이에 먼 타지역에서부터 올라와 직장과 대학교를 오가면서 직접 돈을 벌고 일찍 혼자 사회 생활을 해오면서  힘들지만 2년이란 목표만 채우자라는 마음가짐으로 버텨왔습니다. 하지만 이제 그 노력들이 물거품이 되려합니다. 대통령님 도와주세요 .. 제발 저를 포함한 일학습병행제 친구들이 이번 일학습병행제를 무사히 마무리 할 수 있도록 도와주세요. 1년이란 시간만 기다려주세요 부탁드리겠습니다 저희 미래에 가장 큰 터닝포인트가 될 것입니다.\n",
      "tokenized result ['청소년', '울타리', '죄책감', '양심', '범죄자', '반듯이', '폐지']\n"
     ]
    }
   ],
   "source": [
    "## 각 데이터 길이 확인\n",
    "print('train text counts:', len(train_texts), ', test text counts:', len(test_texts))\n",
    "\n",
    "## train data 원문 및 tokenize 결과 출력\n",
    "print(\"train text sample\", X_train[1])\n",
    "print(\"tokenized result\", train_texts[1])\n",
    "\n",
    "## test data 원문 및 tokenize 결과 출력\n",
    "print(\"test text sample\", X_test[0])\n",
    "print(\"tokenized result\", test_texts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. Word2Vec_English\n",
    "\n",
    "### 1) 미리 학습된 word vector 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "word_vectors = api.load(\"glove-wiki-gigaword-100\")\n",
    "# load pre-trained word-vectors from gensim-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) woman + king - man = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### .most_similar\n",
    "\n",
    "<https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.most_similar>\n",
    "\n",
    "* 단어 벡터의 코사인 유사성을 사용\n",
    "* Find the top-N most similar keys. **Positive keys contribute positively towards the similarity, negative keys negatively.**\n",
    "\n",
    "* This method **computes cosine similarity between a simple mean of the projection weight vectors of the given keys and the vectors for each key in the model.\n",
    "* The method corresponds to the word-analogy(단어 유추) and distance scripts in the original word2vec implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen: 0.7699\n"
     ]
    }
   ],
   "source": [
    "## most_similar\n",
    "result = word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7698541283607483),\n",
       " ('monarch', 0.6843380928039551),\n",
       " ('throne', 0.6755737066268921),\n",
       " ('daughter', 0.6594556570053101),\n",
       " ('princess', 0.6520533561706543),\n",
       " ('prince', 0.6517034769058228),\n",
       " ('elizabeth', 0.6464517116546631),\n",
       " ('mother', 0.631171703338623),\n",
       " ('emperor', 0.6106470823287964),\n",
       " ('wife', 0.6098655462265015)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### .most_similar_cosmul\n",
    "\n",
    "* Omer Levy와 Yoav Goldberg가 제안한 multiplicative combination objective를 사용\n",
    "* Positive words still contribute positively towards the similarity, negative words negatively, **but with less susceptibility to one large distance dominating the calculation.**\n",
    "\n",
    "* In the common analogy-solving case, of **two positive and one negative examples**, this method is equivalent(동등한) to the “3CosMul” objective (equation(방정식) (4)) of Levy and Goldberg.\n",
    "\n",
    "* Additional positive or negative examples contribute to the numerator or denominator, respectively - *a potentially sensible but untested extension of the method.* **With a single positive example, rankings will be the same as in the default most_similar().**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen: 0.8965\n"
     ]
    }
   ],
   "source": [
    "## most_similar_cosmul\n",
    "## positive인 벡터들과 가장 가까우면서, negative와 먼 벡터 찾기\n",
    "result = word_vectors.most_similar_cosmul(positive=['woman', 'king'], negative=['man'])\n",
    "\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 문맥에 안 어울리는 단어 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cereal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Okyoung\\Downloads\\ANACONDA\\lib\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 단어 간 similarity 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Okyoung\\Downloads\\ANACONDA\n",
      "\n",
      "  added / updated specs:\n",
      "    - pyemd\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.9.1                |   py38haa95532_0         2.9 MB\n",
      "    pyemd-0.5.1                |   py38h941acf6_0          64 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  pyemd              pkgs/main/win-64::pyemd-0.5.1-py38h941acf6_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                                        4.8.3-py38_0 --> 4.9.1-py38haa95532_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "conda-4.9.1          | 2.9 MB    |            |   0% \n",
      "conda-4.9.1          | 2.9 MB    |            |   1% \n",
      "conda-4.9.1          | 2.9 MB    | #6         |  16% \n",
      "conda-4.9.1          | 2.9 MB    | ###1       |  32% \n",
      "conda-4.9.1          | 2.9 MB    | ####6      |  47% \n",
      "conda-4.9.1          | 2.9 MB    | ######2    |  63% \n",
      "conda-4.9.1          | 2.9 MB    | #######8   |  78% \n",
      "conda-4.9.1          | 2.9 MB    | #########  |  91% \n",
      "\n",
      "conda-4.9.1          | 2.9 MB    | ########## | 100% \n",
      "\n",
      "pyemd-0.5.1          | 64 KB     |            |   0% \n",
      "pyemd-0.5.1          | 64 KB     | ##4        |  25% \n",
      "pyemd-0.5.1          | 64 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "#pip install pyenmd   #error_can't install\n",
    "#conda install pyemd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "similarity = word_vectors.similarity('woman', 'man')\n",
    "print(similarity > 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 단어 값으로 가장 어울리는 단어 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog: 0.8798\n"
     ]
    }
   ],
   "source": [
    "result = word_vectors.similar_by_word(\"cat\")\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) 문장 간 silmilarity 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyemd import emd\n",
    "from gensim.similarities import WmdSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4893\n"
     ]
    }
   ],
   "source": [
    "sentence_obama = 'Obama speaks to the media in Illinois'.lower().split()\n",
    "sentence_president = 'The president greets the press in Chicago'.lower().split()\n",
    "\n",
    "similarity = word_vectors.wmdistance(sentence_obama, sentence_president)\n",
    "print(\"{:.4f}\".format(similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) 단어 간 distance 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "distance = word_vectors.distance(\"media\", \"media\")\n",
    "print(\"{:.1f}\".format(distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어 여러개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7067\n"
     ]
    }
   ],
   "source": [
    "sim = word_vectors.n_similarity(['sushi', 'shop'], ['japanese', 'restaurant'])\n",
    "print(\"{:.4f}\".format(sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어 넣어서 vector shape 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "vector = word_vectors['computer']  # numpy vector of a word\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-b120fd60d724>:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  vector = word_vectors.wv.word_vec('office', use_norm=True)\n"
     ]
    }
   ],
   "source": [
    "vector = word_vectors.wv.word_vec('office', use_norm=True)\n",
    "print(vector.shape)\n",
    "#<ipython-input-40-b120fd60d724>:1: DeprecationWarning: Call to deprecated `wv`\n",
    "#(Attribute will be removed in 4.0.0, use self instead)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. Word2Vec_Petition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train\n",
    "from gensim.models import word2vec\n",
    "\n",
    "wv_model_ko = word2vec.Word2Vec(train_texts)\n",
    "wv_model_ko.init_sims(replace=True)\n",
    "\n",
    "wv_model_ko.save('petition_sample_w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('소년법', 0.9942440986633301), ('악용', 0.9921799898147583), ('폐지', 0.9891029596328735), ('테두리', 0.9859112501144409), ('범죄', 0.9833984375), ('성인', 0.9796206951141357), ('소년원', 0.977559506893158), ('소년', 0.9745475649833679), ('나이', 0.9741848111152649), ('피해자', 0.9739570617675781)]\n"
     ]
    }
   ],
   "source": [
    "## 유사한 단어 추출\n",
    "print(wv_model_ko.wv.most_similar('청소년'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['저희', '학습', '병행', '제라', '제도', '직장인', '대학생', '저희', '고등학교', '학습', '병행', '제로', '취업', '시작', '완료', '과정', '학습', '병행', '법률', '이상', '학습', '병행', '제도', '실시', '업체', '폐지', '상황', '당장', '이번', '중순', '시기', '이후', '저희', '강제', '학습', '병행', '저희', '지금껏', '시간', '나이', '나이', '지역', '직장', '대학교', '오가면', '직접', '일찍', '혼자', '사회', '생활', '목표', '마음가짐', '이제', '노력', '거품', '대통령', '제발', '포함', '학습', '병행', '친구', '이번', '학습', '병행', '마무리', '시간', '저희', '미래', '가장', '터닝', '포인트']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Okyoung\\Downloads\\ANACONDA\\lib\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'대통령'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  다른 단어들과 가장 거리가 먼 단어\n",
    "print(test_texts[0])\n",
    "wv_model_ko.wv.doesnt_match(test_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tagged data 만들기\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "tagged_data = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_texts)]\n",
    "dv_model = Doc2Vec(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vector로 변환\n",
    "dv_train = [dv_model.infer_vector(doc) for doc in train_texts]\n",
    "dv_test = [dv_model.infer_vector(doc) for doc in test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dv_train)   #dv 길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00748427,  0.00483338, -0.00131175,  0.00467666, -0.02133227,\n",
       "        0.01176464,  0.00436749, -0.00287836, -0.0008799 , -0.01163244,\n",
       "       -0.01002939,  0.00193803, -0.01616644,  0.00908489,  0.00276463,\n",
       "        0.00130881, -0.00606492,  0.00864812,  0.00242354, -0.00811363,\n",
       "       -0.01334949, -0.01459219,  0.01011735, -0.00146063, -0.01338328,\n",
       "        0.00824748,  0.02833881,  0.00122824,  0.01558639,  0.00957044,\n",
       "        0.0028697 ,  0.00404345, -0.00096915,  0.01160685, -0.00519978,\n",
       "        0.00044569,  0.00184421,  0.01734841, -0.00519189, -0.00561948,\n",
       "       -0.00348942, -0.00855845, -0.00272448,  0.02142694,  0.01783529,\n",
       "        0.01751464, -0.01244238, -0.00123217, -0.01733058, -0.01387348,\n",
       "       -0.0027636 , -0.0024836 , -0.0049856 , -0.00857475,  0.0112785 ,\n",
       "        0.00438794,  0.0034015 ,  0.00932605,  0.00188516, -0.01413359,\n",
       "       -0.00706821, -0.00115823,  0.00455657, -0.00822875, -0.01627369,\n",
       "        0.00325782, -0.01405371, -0.01250457, -0.00187487,  0.00874967,\n",
       "        0.00341663, -0.00615451, -0.00032709, -0.00905321, -0.00937141,\n",
       "        0.00095599,  0.01740404,  0.00927292,  0.00608523, -0.00852233,\n",
       "        0.00495007,  0.00479007,  0.00376915, -0.0047579 , -0.01418581,\n",
       "        0.00177351,  0.0077709 ,  0.00789424, -0.01527817,  0.00827432,\n",
       "       -0.00555978, -0.00260505, -0.00384162,  0.00365427, -0.01671416,\n",
       "        0.00050121, -0.01493867,  0.00893725,  0.0011222 , -0.01116418],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.684\n",
      "Test set score: 0.642\n"
     ]
    }
   ],
   "source": [
    "## 학습 및 성능체크\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "clf = LogisticRegression() #분류기 선언\n",
    "clf.fit(dv_train, y_train) # train data를 이용하여 분류기를 학습\n",
    "print('Train set score: {:.3f}'.format(clf.score(dv_train, y_train))) # train data에 대한 예측정확도 \n",
    "print('Test set score: {:.3f}'.format(clf.score(dv_test, y_test))) # test data에 대한 예측정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.717\n",
      "Test set score: 0.673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Okyoung\\Downloads\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "## StandatdScaler로 dv_train, dv_test 스케일 조정\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sc_train = scaler.fit_transform(dv_train)\n",
    "sc_test = scaler.transform(dv_test)\n",
    "\n",
    "## 재학습 및 성능체크\n",
    "clf.fit(sc_train, y_train) # train data를 이용하여 분류기를 학습\n",
    "print('Train set score: {:.3f}'.format(clf.score(sc_train, y_train))) # train data에 대한 예측정확도 \n",
    "print('Test set score: {:.3f}'.format(clf.score(sc_test, y_test))) # test data에 대한 예측정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(624, 0.9955933094024658),\n",
       " (246, 0.9938916563987732),\n",
       " (2801, 0.9936037063598633),\n",
       " (11, 0.9905550479888916),\n",
       " (2292, 0.9894212484359741),\n",
       " (1004, 0.9886334538459778),\n",
       " (947, 0.9880856275558472),\n",
       " (920, 0.9878066778182983),\n",
       " (2016, 0.9876843094825745),\n",
       " (491, 0.9873559474945068)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# offset=1인 문서(train_text의 2번째 문서)와가장 비슷한 문서들 출력\n",
    "dv_model.docvecs.most_similar(1)   #624번째 문서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'문재인 대통령님, 국정을 책임 지느라 수고가 많습니다 항상 마음속으로 응원하고 지지합니다\\\\n저는 대기업 통신사들의 협력업체 에서 일을하는 외주 노동자 입니다\\\\n우리 문재인 정부가 서민을 위하고 사람이 먼저이다 라는 국정철학에  부합 하고자 한다면 진정 현실을\\\\n좀더 면면희 들여다 보고 아셔야 합니다  안타깝습니다\\\\n우선, 제가 생업으로 하고있는 일자리 수입원 구조부터 말씀 드리겠습니다\\\\n저는 통신공사 관련일을 하고 있는 외주 노동자 생활을 근 20여년 해오고 있는 가장 입니다\\\\n아이가 3명이고 이일을 해서 아이들을 키우고 있습니다\\\\n물런 단한번도 안정적 이고 고정적인 수입이 없었습니다  그러면 우리나라 통신사 대기업들의 구조를\\\\n보면 이들은 협력업체를 지역구에 두어서 모든 설치 시공 설비 관련 현장일을 시키고 있습니다\\\\n그 영세한 협력업체들은 대부분 외주 일용직 노동자 들을 (기능직 이죠) 저의관점 에서는\\\\n그 일을 생업으로 하는 것이 고정급여제가 아니고 대부분 한건당 얼마의 정액제 입니다\\\\n그러다 보니 수입은 불안정 하고 일이 있을떄는 하고 없으면 못하고 그런실정 입니다\\\\n그것까지 탓을 할수는 없다는것은 알고 있습니다\\\\n이일에 종사하는 사람들이 전국에 적지 않습니다,\\\\n그간 대기업들의 협력업체들 에게 갑질이니, 머니 그런것은 둘째로 치고 넘어 간다고 해도\\\\n임금 지급은 당연히 대기업 에서 먼저 물어야 하는데  온갇 이유를 들어 일을한지 월수로는 3개월 인데도\\\\n미비한것이 있다고 하여, 한푼도 지급하지 않고 있는 이런 행태를 과연\\\\n누가 진정 단한사람도 알고나 있는지요\\\\n대기업협력사 들은 고양이 목에 방울거는 형태라 말한마디도 못하고  그 영세한 협력업체들은\\\\n대기업들 에서 정산이 안되었다고 하며 돈을 지급하지 않고\\\\n그러면 그 노동자 들은 어떻겠습니까?\\\\n그런 오랜 악습이 수십년 동안 진행 되다가 지금은 다소 개선이 된줄알고 있는데 예전보다는 나아졌는데\\\\n이들 대기업들의 해묵은 악습은 또다시 명절을 앞두고 있는 지금 이시점에 벌어지고 있습니다\\\\n하물며 정부 발주공사를 대기업이 진행하는 지금\\\\n그런 공사를 진행하는것에 수많은 인력 자재 물품 기타등 용역이 소비대면서 벌어지는 것에  얼마나\\\\n담당부서자는 파학 이라도 하고 있는지 너무나 안타깝네요\\\\n대기업들 직원들 급여 한두달 지급 하지않는다면 난리가 나겠죠>??\\\\n그런데 우리 일용직 노동자 들은 한두달은 돈이 안나왔다 하면 그냥 끝입니다\\\\n가장 일선에서 가장 힘들고 열악한 조견 환경에서 힘든일을 하고 있는 현장 노동자 들의 처우개선은\\\\n바라지도 않습니다\\\\n다만 일한것에 대해서 최소한 전액은 지급 못하더라도 이들이 생활은 유지할수 있게금\\\\n어느정도 돈을 풀어 주어야 생활이되고 가족이 그돈으로 먹고살고\\\\n소비를하고, 그래야 하는것 아닌가요\\\\n대기업 에서는 정부발주 사업을 대신하여 하는 주사업자 이면 자신들이 먼저 자재비 임금등을 지급 하면서\\\\n진행하는 것이 상식 아닙니까?\\\\n그런데 요건이나 구비서류등을 미비한것이 있다는 온갇 이유를 들어 한푼도 지급하지 않으니\\\\n영세한 협력업체들은 자재비 경비 노무비 급여등을 한두달 어떻게 감당 하나요?\\\\n단순하게 물품구입 이라면 덜하겠지만 정부에서 시설공사를 통한  설비 장비 설치 공사를 통한 일이면\\\\n그에 수반되는 여러가지 구매대금 용역 인건비 경비 등에 대한것과 그것에 종사하는 노동자들의 임금도\\\\n최소한 어떻게 지급이 되고 있는지 관심이라도 표현 해주면\\\\n이런 대기업들이 이따위로 하겠습니까?\\\\n대기업 자신들은 혁신이니 원가절감이니 하면서 그 협력업체들은 몇번을 가고 또가고 반복을 해서 마쳐야 하는\\\\n상황을 만들어 놓고 자신들의 비용이 나가는 것이 아니기에 강요와 닥달만 하지\\\\n이들을 도와주어 어떻게 하면 협력사와 종사자들 에게 도움을 줄수있을까 고민하는\\\\n대기업 담당자 들은 단한명도 없습니다\\\\n최소한 정부예산 으로 정부 발주사업 이면. 이런 대기업 들의 횡포는 견제하고 감독을 할수있어야 하는것\\\\n아닙니까,.?  우리 노동자 들이 생존문재 임금에 대해서 관심을 가져 주시기를 간곡희 부탁드립니다\\\\n이런 악습의 관행이 어디 통신사 들 뿐입니까?\\\\n열이면 열 백이면 그중 거의 대부분 이런 악습의 관행을 이어가고 있습니다, 다른 업종도\\\\n그러면 그 종사자들의 수입은 불안정 하고 수입이 없으니 소비는 당연희 없고 그래도 일은 해야겠으니\\\\n속티 터지고 부당하고 억울해도 속을 태워 가면서 위험하고 힘든일을 해오던 일이라\\\\n참아내며 하고 있습니다,\\\\n다음주면 추석 명절 입니다,. 환경부 에서 발주한  공사를 하는 대기업 협력업체 에서 일하는 사람으로서\\\\n환경부가 대기업 에게 공사비를 지급 안하면 대기업이 사업원청 이니\\\\n대기업 에서 추석명절을 앞두고 있는데도 전혀 지급을 하지 않는다고 하면 외 환경부는\\\\n대기업들만 이런 공사를 선정 합니까, 이런 문재포함 해서 사업을 할수있는 역량이 되니 맡긴것 아닌가요,.\\\\n너무나 부당하고 속상 합니다 협력업체 들에게는 원성을 내고 큰소리를 내보아도 대기업 들이\\\\n결재를 하지않고 있어서 자기들도 가진돈을 다풀어서 돈이없다,\\\\n그런데도 그  대기업들은 추석명절에는 직원들 에게는 급여와 보너서 선물꾸러미는 주겠죠.\\\\n공사비는 이익은 대기업이 다 빼먹고  힘들고 어려운 일을 하는 협력업체들은 그 부스러기 주워 먹으려\\\\n끽소리도 못하고 그곳에 종사해서 생업을 이어가는 노동자 들은 누구를 원망하고 한탄 해야 합니까,.\\\\n정말 담당 공무원의 무능과 관심부족을 질타 할수밖에 없습니다,\\\\n하여, 바라건데 환경부 가 주관하고 있는 전기 자동차 사업관련 싸이클을 한번 점검 해주시고\\\\n그에 종사하는 여러가지 업체 자재 장비 공사업 노동자 이들의 처우개선을 바라지도 않습니다\\\\n다면  이들이 일한것에 대해서는 매달 일한만큼은 임금이 지급 될수 있도록 제도나 환경을 개선 해주기를\\\\n부탁 드립니다,\\\\n외냐, 최소한 민자공사도 아니고 정부 부처 발주공사 이면,  최소한 그에 수반대는 것에 자재 장비 임금등에\\\\n대해서는 그사업자가 책임을 질수있는 업체를 선정하고 그에 책임을 확인하는 이행하는것을 감독하는\\\\n공무원이 있다면 얼마나 많은 사람들이  편해 지겠습니까\\\\n이런 일들이 비일비재 하겠지만, 어떤 정부도 어느 공무원도 누구도 관심조차 없는 이런 행태를 파학하고\\\\n조금 이라도 개선의 여지가 있는지 관심을 가져 주시고 고쳐 주시면\\\\n사람이 먼저이다, 국정철학에 매우 진정 더 따뜻한 더운 가슴으로 문재인 정부가 온전하게 다가 오리라 믿습니다\\\\n제발 바라건데 노동자 들의 임금문재는 민자공사든 관급 공사든 어떤 식으로든 정부가 강력하게 선도하여\\\\n이런 오래된 악습과 폐해를 지금 이라도 조사를 하고 수정을 하여\\\\n사람이 먼저이다 라는 문재인 정부 철학에 부합되게 관심을 가져 주시고 감독을 부탁 드립니다\\\\n마지막으로 환경부 는 지금 발주한 공사에 대해서는  수급 사업자 에게는 그에 종사하는 노동자 들의\\\\n임금을 지급될수 있게 관리 감독을 해주시기를 간곡희 바랍니다,'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]   #입력한 1번 문서와 아래 624번 문서 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요. 저는 청년창업하여 광고회사를 이끌어가고 있는 작은 회사의 대표자입니다.\\\\n정부는 일자리 창출의 일환으로 청년창업을 유도하고 있고 많은 지원정책들을 시행하고 있어, 저도 지금까지 사업을\\\\n잘 영위해 나가고 있습니다.\\\\n저희 업종은 아이디어와 커뮤니케이션 스킬이 중요한 광고대행업 입니다. 이 분야에 저희 광고주는 정부기관이나 공공기관이 포함되어 있는데요. 항상 겪는 일이지만 정부/공공기관은 한국언론재단을 통해 계약을 하더군요.\\\\n저희가 영업과 미팅을 통해 광고 캠페인안을 만들고 예산을 제안하여 광고안이 확정되면, 언론재단이 뜬금없이\\\\n나타나 저희가 협의를 통해 확정한 광고안에 대해 10%의 수수료를 가져갑니다.\\\\n저는 이 구조가 도통 이해가 가지 않아 몇 가지 찾아보던 중 국무총리 훈령 제 541호에 의거 정부/공공기관 광고는\\\\n언론재단을 통해 해야 한다는 사실을 알게 되었습니다. 유독 광고 업종에만 이런 재단이 존재하는데.. 들리는 소문에\\\\n의하면 박정희 대통령 시절에 자금 조성용도로 만들어 졌다는 얘기도 들었습니다.\\\\n물론 정부/공공기관의 모든 광고업무가 언론재단을 통하지는 않습니다. 나라장터를 통한 입찰도 존재합니다.\\\\n나라장터를 통한 입찰은 저희 입장에서는 준비과정이 고생스럽기는 해도 언론재단을 통한 계약보다는 훨씬 더 투명하고 회사를 운영하는 면에서 도움이 많이 됩니다.\\\\n저는 다음과 같이 제안 드리는 바입니다.\\\\n1. 언론재단을 통한 정부/공공기관 광고대행 업무를 환원하고\\\\n2. 나라장터 입찰 또는 수요기관 자체 수의계약으로 광고 업무를 진행할 것을 요청드립니다.\\\\n이렇게 하면\\\\n1. 민간 광고회사의 수익증대로 창업 및 일자리 창출에 기여할 수 있고\\\\n2. 수요기관에서도 광고관련 인력의 채용을 도모할 수 있겠습니다.\\\\n감사합니다.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[624]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
