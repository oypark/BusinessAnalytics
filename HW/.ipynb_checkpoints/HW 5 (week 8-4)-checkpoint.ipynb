{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Bigram News Group(N-gram)\n",
    "\n",
    "## 1. 20 Newsgroups\n",
    "\n",
    "### 1) 20 Newsgroups data 준비\n",
    "\n",
    "<http://scikit-learn.org/0.19/datasets/twenty_newsgroups.html>\n",
    "\n",
    "* The 20 newsgroups dataset comprises **around 18000 newsgroups posts on 20 topics** split in two subsets: **one for training** (or development) and **the other one for testing** (or for performance evaluation).\n",
    "* The split between the train and test set is based upon a **messages posted before and after a specific date.**\n",
    "\n",
    "---\n",
    "\n",
    "* train set과 test set이 별도로 분리되어 있음.\n",
    "* categories 매개변수를 이용하여 20개의 topic 중에서 원하는 topic을 선택할 수 있음\n",
    "* remove를 이용하여 필요없는 부분을 삭제할 수 있음\n",
    "* 각 set 내에서 .data 는 text 내용을, .target은 숫자로 변경된 label(category)를 가져오는 데 사용됨\n",
    "* 따라서 20 newsgroups는 train_test_split을 이용하여 train set과 test set을 분리할 필요가 없음\n",
    "\n",
    "### 2) category 선정하여 training, test 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "#4개의 카테고리 선택\n",
    "\n",
    "#학습 및 테스트 진행\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      #메일 내용에서 hint가 되는 부분을 삭제 - 순수하게 내용만으로\n",
    "                                      categories=categories)   #4개의 카테고리로만 진행\n",
    "\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', \n",
    "                                     remove=('headers', 'footers', 'quotes'),\n",
    "                                     categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 2034\n",
      "test set size: 1353\n",
      "selected categories: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
      "train labels: {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "print('train set size:', len(newsgroups_train.data))   #.data로 text 불러오기\n",
    "print('test set size:', len(newsgroups_test.data))\n",
    "print('selected categories:', newsgroups_train.target_names)   #.target은 카테고리 숫자, _names는 이름 불러오기\n",
    "print('train labels:', set(newsgroups_train.target))   #카테고리 label 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##Train set text samples: Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "##Train set label smaples: 1\n",
      "##Test set text samples: TRry the SKywatch project in  Arizona.\n",
      "##Test set label smaples: 2\n"
     ]
    }
   ],
   "source": [
    "# train, test set text 및 label 결과 확인하기\n",
    "print('##Train set text samples:', newsgroups_train.data[0])\n",
    "print('##Train set label smaples:', newsgroups_train.target[0])\n",
    "print('##Test set text samples:', newsgroups_test.data[0])\n",
    "print('##Test set label smaples:', newsgroups_test.target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) text document classification\n",
    "* newsgroups_train과 newsgroups_test로부터 .data와 .target을 이용하여 X_train, X_test, y_train, y_test을 추출하여 text document classification을 수행하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text 추출\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "\n",
    "# label(카테고리) 추출\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords(자주 쓰이지만 분석에 의미가 없는 단어들) 중 영어만 추출\n",
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 11483)\n"
     ]
    }
   ],
   "source": [
    "# text로부터 TFIDF 직접생성\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(token_pattern= \"[a-zA-Z']{3,}\",   # 알파벳 3개 이상의 단어만 tokenize \n",
    "                        decode_error ='ignore',    #decode error 무시\n",
    "                        lowercase=True,    #소문자로 변경\n",
    "                        stop_words = stopwords.words('english'), \n",
    "                        max_df=0.5,   #단어가 포함된 최대 문서 비율(문서 전체 중 50%가 넘게 들어가 있는 단어는 제외)\n",
    "                        min_df=2    #단어가 포함된 최소 문서 개수\n",
    "                       ).fit(X_train)\n",
    "\n",
    "X_train_tfidf = tfidf.transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.966\n",
      "Test set score: 0.761\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 성능체크\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "clf = LogisticRegression() #분류기 선언\n",
    "clf.fit(X_train_tfidf, y_train) # train data를 이용하여 분류기를 학습\n",
    "print('Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train))) # train data에 대한 예측정확도 \n",
    "print('Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) # test data에 대한 예측정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. N-gram\n",
    "* 문맥(context)를 파악하기 위한 전통적 방법\n",
    "* 대상이 되는 문자열을 하나의 단어 단위가 아닌, 두 개 이상의 단위로 잘라서 처리\n",
    "* 보통 unigram에 bi-gram, tri-gram을 추가하면서 feature의 수가 증가시켜 사용\n",
    "\n",
    "### 1) Bigram\n",
    "* text, 즉 문자열을 2개의 단어씩 잘라서 tokenize하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 26550)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(token_pattern= \"[a-zA-Z']{3,}\", \n",
    "                        decode_error ='ignore', \n",
    "                        lowercase=True, \n",
    "                        stop_words = stopwords.words('english'),\n",
    "                        ngram_range=(1, 2),   #bigram으로 설정\n",
    "                        max_df=0.5,\n",
    "                        min_df=2).fit(X_train)\n",
    "X_train_tfidf = tfidf.transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'cause can't\", \"'em better\", \"'expected errors'\", \"'karla' next\", \"'nodis' password\", \"'official doctrine\", \"'ok see\", \"'sci astro'\", \"'what's moonbase\", 'aas american']\n"
     ]
    }
   ],
   "source": [
    "bigram_features = [f for f in tfidf.get_feature_names() if len(f.split()) > 1]\n",
    "print(bigram_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.969\n",
      "Test set score: 0.756\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression() #분류기 선언\n",
    "clf.fit(X_train_tfidf, y_train) # train data를 이용하여 분류기를 학습\n",
    "print('Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train))) # train data에 대한 예측정확도 \n",
    "print('Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) # test data에 대한 예측정확도\n",
    "\n",
    "# train score는 unigram 보다 상승, test score는 성능이 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Trigram\n",
    "* 문자열을 3개의 단어씩 끊어서 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 32943)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(token_pattern= \"[a-zA-Z']{3,}\", \n",
    "                        decode_error ='ignore', \n",
    "                        lowercase=True, \n",
    "                        stop_words = stopwords.words('english'),\n",
    "                        ngram_range=(1, 3),  #trigram\n",
    "                        max_df=0.5,\n",
    "                        min_df=2).fit(X_train)\n",
    "X_train_tfidf = tfidf.transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'em better shots\", \"'expected errors' basically\", \"'karla' next one\", \"'nodis' password also\", \"'official doctrine think\", \"'ok see warning\", \"'what's moonbase good\", 'aas american astronautical', 'ability means infallible', 'able accept donations']\n"
     ]
    }
   ],
   "source": [
    "trigram_features = [f for f in tfidf.get_feature_names() if len(f.split()) > 2]\n",
    "print(trigram_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.969\n",
      "Test set score: 0.758\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression() #분류기 선언\n",
    "clf.fit(X_train_tfidf, y_train) # train data를 이용하여 분류기를 학습\n",
    "print('Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train))) # train data에 대한 예측정확도 \n",
    "print('Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) # test data에 대한 예측정확도\n",
    "\n",
    "# train score는 unigram보다 상승, test는 성능이 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.976\n",
      "Test set score: 0.775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_clf = RidgeClassifier() #릿지 분류기 선언\n",
    "ridge_clf.fit(X_train_tfidf, y_train) #학습\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "# train, test score 모두 현재까지 가장 좋은 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.761\n",
      "Test set score: 0.695\n",
      "Used features count: 246 out of 32943\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear') # Lasso는 동일한 LogisticRegression을 사용하면서 매개변수로 지정\n",
    "lasso_clf.fit(X_train_tfidf, y_train) # train data로 학습\n",
    "print('Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "print('Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1]) \n",
    "\n",
    "# 현재까지 train, test 모두 성능이 가장 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) SVM(Support Vector Machine)\n",
    "* 결정 경계(Decision Boundary), 즉 분류를 위한 기준 선을 정의하는 모델\n",
    "* 분류되지 않은 새로운 점이 나타나면 경계의 어느 쪽에 속하는 지 확인해서 분류 과제를 수행\n",
    "\n",
    "* 데이터 속성(feature)가 2개 일 때, 결정 경계 그래프 예시\n",
    "![alt text](https://i0.wp.com/hleecaster.com/wp-content/uploads/2020/01/svm01.png?w=1372 \"wp-image-5017 jetpack-lazy-image jetpack-lazy-image--handled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.974\n",
      "Test set score: 0.758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='auto', kernel='linear')\n",
    "clf.fit(X_train_tfidf, y_train) \n",
    "print('Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train))) # train data에 대한 예측정확도 \n",
    "print('Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) # test data에 대한 예측정확도\n",
    "\n",
    "# train score은 ridge 다음으로 높고, test는 ridge, unigram 다음으로 높음(3 번째)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train, test set score 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uni-gram</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bi-gram</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tri-gram</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ridge</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lasso</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     method  train   test\n",
       "0  uni-gram  0.966  0.761\n",
       "1   bi-gram  0.969  0.756\n",
       "2  tri-gram  0.969  0.758\n",
       "3     ridge  0.976  0.775\n",
       "4     lasso  0.761  0.695\n",
       "5       svm  0.974  0.758"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "scores = pd.read_csv('C:/Users/Okyoung/Desktop/Business Analytics_캡스톤디자인/BusinessAnalytics/HW/compare_score2.csv')\n",
    "\n",
    "scores   #ridge가 train, test 모두 가장 좋은 성능을 보유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
