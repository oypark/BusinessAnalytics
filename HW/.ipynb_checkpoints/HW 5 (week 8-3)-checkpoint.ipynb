{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Text Classification(Korean)\n",
    "\n",
    "## 1. 한글 문서의 분류\n",
    "\n",
    "* 다음무비<http://movie.daum.net>로부터 crawl한 영화리뷰를 이용하여 분류 연습\n",
    "* 영화리뷰와 영화의 제목을 학습해서 주어진 리뷰내용으로 어떤 영화에 대한 리뷰인지를 예측하고자 함\n",
    "\n",
    "#### data file 내용\n",
    "*'신과함께', '코코', '라라랜드', '인피니티 워', '곤지암' 다섯개의 영화에 대해 총 1827개의 리뷰를 수집 csv 파일 안에 리뷰내용, 평점, 영화이름 의 순으로 저장되어 있음\n",
    "\n",
    "### 1) data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#초기화\n",
    "text = []    #영화리뷰\n",
    "y = []     #영화제목\n",
    "\n",
    "with open('movie_data.csv', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        #print(row)\n",
    "        if row: #그 줄에 내용이 있는 경우에만(NA 제외)\n",
    "            text.append(row[0]) #영화 리뷰를 text 리스트에 추가\n",
    "            y.append(row[2]) #영화이름을 text 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of samples: 1827\n",
      "Movie titles of reivews: {'코코', '신과함께', '곤지암', '인피니티 워', '라라랜드'}\n"
     ]
    }
   ],
   "source": [
    "print('Num of samples: {}'.format(len(text)))    #총 리뷰수 보기\n",
    "print('Movie titles of reivews: {}'.format(set(y)))   #영화제목 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) training set, test set으로 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, y, random_state=0)\n",
    "# 비율을 지정하지 않으면 75:25로 분할됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1370"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)   #1872의 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 형태소 분석기 활용해 형태소 단위로 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt #konlpy에서 Twitter 형태소 분석기를 import\n",
    "#from konlpy.tag import Twitter #konlpy에서 Twitter 형태소 분석기를 import\n",
    "\n",
    "twitter_tag = Okt()\n",
    "#twitter_tag = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['혹시', '나', '하고', '봤는데', '역시', '나다', ';;', '편집', '과', '사운드', '로', '주는', '작은', '공포', '영화', \"'\", '푸시', \"'\", '에서', '인상', '깊게', '봤던걸', '여기', '서', '또', '보네', ';;']\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.morphs(X_train[1])) #둘째 리뷰에 대해 형태소 단위로 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['혹시', '역시', '편집', '사운드', '공포', '영화', '푸시', '인상', '여기', '또']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_tag.nouns(X_train[1]) #둘째 리뷰에서 명사만 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 명사만 추출하는 tokenizer 함수를 생성한 뒤 분류기(classifier) 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter 형태소 분석기의 명사만 추출하는 함수를 tokenizer 함수로 사용\n",
    "def twit_tokenizer(text):\n",
    "    return twitter_tag.nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8364963503649635\n",
      "Test score 0.6717724288840262\n",
      "(1370, 1156)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## 명사만 추출하는 tokenizer 함수 이용\n",
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=2)\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "#twit_tokenizer 대신 twitter_tag.nouns를 직접 써도 됨\n",
    "#하나의 문서에서만 출현한 단어는 쓸모가 없으므로 제외, 즉 최소 document frequency를 2로 설정\n",
    "\n",
    "## train set, test set을 vector로 변환\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train data 변환 -> tfidf vector\n",
    "X_test_tfidf = tfidf.transform(X_test) # test data 변환 -> tfidf vector\n",
    "\n",
    "## 분류기 학습 및 예측정확도 확인\n",
    "clf = LogisticRegression() # logistic regression 분류기 선언\n",
    "clf.fit(X_train_tfidf, y_train) # 분류기 학습\n",
    "\n",
    "print('Train score', clf.score(X_train_tfidf, y_train)) # train data 예측정확도\n",
    "print('Test score', clf.score(X_test_tfidf, y_test)) # test data 예측정확도\n",
    "print(X_train_tfidf.shape) # 총 1156개의 명사로 이루어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) test set과 예측내용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['졸잼 최고',\n",
       " '내용, 음악 , 연기력  무엇하나 빠지는것이 없네요 특히 음악은 계속 찾아 듣게되요^^',\n",
       " '아맥2D로 느즈막히 관람.... 히어로가 많이나오지만, 이걸 꽤나 잘 버무려놓음. 뻔한스토리의 틀을 벗어나려 노력한점은 높은점수를 줄만함.... 블럭버스터액션, 영상미는 말이필요없음...... 후속편 기대됨!',\n",
       " '후반부터 쫄렸다.',\n",
       " '진짜. 솔직히 한국 공포영화중에 이렇게 소재별로인건 정말 오랜만인듯; 지들끼리 소리지르고 정신없이 우왕자왕 심지어 무섭지도않어 효과음만크고 진짜최악임ㅉㅉ',\n",
       " '소문난 잔치에 먹을거 없음..ㅜㅜ',\n",
       " 'good!',\n",
       " '아 점수를 줄 수가 없네  화면은 왜그리도 흔들어 데는지........ 재미도 없고 가볍기만하고 .... 최악의 재미없는 배멀미 영화',\n",
       " '영화 보면서 펑펑물었네요~ 부모님 사랑에 대해 다시한번 생각하게 했던 영화네요^ ^',\n",
       " '슬픈 스토리지만 삶을 돌아보게 하는 영화다. 죄를 지은자는 그 벌을 고스란히 받으리라. 사회 각종범죄자들 뉘우치길 바란다.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:10] #test data에서 앞 10개를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['인피니티 워', '라라랜드', '인피니티 워', '곤지암', '곤지암', '인피니티 워', '인피니티 워',\n",
       "       '신과함께', '코코', '신과함께'], dtype='<U6')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test_tfidf[:10]) # test data의 앞 10개에 대한 예측내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['인피니티 워', '라라랜드', '인피니티 워', '곤지암', '곤지암', '인피니티 워', '인피니티 워', '곤지암', '신과함께', '신과함께']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:10]) # test data 앞 10개의 실제 영화제목 #맨 뒤 곤지암, 신과함께 빼고 맞음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 성능을 개선하기 위한 노력\n",
    "\n",
    "### 1) 명사 이외에도 다른 형태소도 모두 포함해 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['혹시', '나', '하고', '봤는데', '역시', '나다', ';;', '편집', '과', '사운드', '로', '주는', '작은', '공포', '영화', \"'\", '푸시', \"'\", '에서', '인상', '깊게', '봤던걸', '여기', '서', '또', '보네', ';;']\n"
     ]
    }
   ],
   "source": [
    "# morphs()는 명사를 포함한 모든 형태소를 tokenize\n",
    "print(twitter_tag.morphs(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8963503649635036\n",
      "Test score 0.649890590809628\n",
      "(1370, 2260)\n"
     ]
    }
   ],
   "source": [
    "## 명사 대신 모든 형태소를 사용\n",
    "tfidf = TfidfVectorizer(tokenizer=twitter_tag.morphs, min_df=2)\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "\n",
    "## vector로 변환\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "## train set 학습 및 성능확인\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)   #명사만 사용한 것에 비해 train score는 상승, test score는 하락"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 명사, 동사, 형용사만 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('혹시', 'Noun'), ('나', 'Josa'), ('하다', 'Verb'), ('보다', 'Verb'), ('역시', 'Noun'), ('나다', 'Verb'), (';;', 'Punctuation'), ('편집', 'Noun'), ('과', 'Josa'), ('사운드', 'Noun'), ('로', 'Josa'), ('주다', 'Verb'), ('작다', 'Adjective'), ('공포', 'Noun'), ('영화', 'Noun'), (\"'\", 'Punctuation'), ('푸시', 'Noun'), (\"'\", 'Punctuation'), ('에서', 'Josa'), ('인상', 'Noun'), ('깊다', 'Adjective'), ('보다', 'Verb'), ('여기', 'Noun'), ('서', 'Josa'), ('또', 'Noun'), ('보다', 'Verb'), (';;', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "#pos()는 형태소와 품사를 함께 제공\n",
    "print(twitter_tag.pos(X_train[1], norm=True, stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer2(text): #전체를 다 사용하는 대신, 명사, 동사, 형용사를 사용\n",
    "    target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "            #result.append('/'.join([word, tag]))  -> 뒤에서는 이걸로해서 단어의 품사를 구분할 수 있도록!\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['혹시', '하다', '보다', '역시', '나다', '편집', '사운드', '주다', '작다', '공포', '영화', '푸시', '인상', '깊다', '보다', '여기', '또', '보다']\n"
     ]
    }
   ],
   "source": [
    "print(twit_tokenizer2(X_train[1])) # 사용 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8715328467153285\n",
      "Test score 0.6849015317286652\n",
      "(1370, 1584)\n"
     ]
    }
   ],
   "source": [
    "## 명사, 동사, 형용사를 이용하여 tfidf 생성\n",
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer2, min_df=2)\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "\n",
    "## vector로 변경\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "## 학습 및 성능체크\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "# 현재까지 중에서 test score가 가장 뛰어남"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 모든 형태소를 다 사용해 tokenize + 품사 구분할 수 있도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 형태소를 다 사용하고 품사를 알 수 있도록 하면?\n",
    "def twit_tokenizer3(text):\n",
    "    #target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        result.append('/'.join([word, tag])) #단어의 품사를 구분할 수 있도록 함\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8927007299270073\n",
      "Test score 0.6739606126914661\n",
      "(1370, 2023)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer3, min_df=2)\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "#성능이 오히려 떨어지고 품사 표시 없이 전체를 다 사용한 경우에 비해 train은 떨어지고, test는 올라감"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Ridge regression(릿지 회귀)\n",
    "\n",
    "#### Logistic regression 회귀 분석\n",
    "* 종속 변수와 독립 변수간의 관계를 구체적인 함수로 나타내어 향후 **예측 모델에 사용**\n",
    "* 종속 변수가 범주형 데이터를 대상으로 하며, 입력 데이터가 주어졌을 때 해당 **데이터의 결과가 특정 분류로 나뉘기때문에 일종의 분류 (classification) 기법에 해당**\n",
    "* 하지만 텍스트 마이닝에서는 추정해야 할 계수가 vector의 크기(단어의 수)만큼 존재하므로, 과적합이 발생하기 쉽고 많은 데이터 셋이 필요 \n",
    "* 그럼에도 불구하고 잘 작동하는 편이며 정규화(regulation)을 이용해 과적합 해결 노력\n",
    "\n",
    "#### Ridge regression\n",
    "* 목적 함수에 추정할 계수(parameter)에 대한 **L2 norm(규제항)을 추가하여 모형의 과적합을 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.944\n",
      "Test set score: 0.676\n"
     ]
    }
   ],
   "source": [
    "# train score가 높으므로 ridge를 쓰면 어떨까?\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_clf = RidgeClassifier(alpha = 1)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "# train score가 올라가는 현상이 벌어짐\n",
    "# test score가 올라갔으나 명사, 형용사, 동사를 쓴 것보다 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Lasso regression(라쏘 회귀)\n",
    "\n",
    "#### Lasso regression\n",
    "* L1 norm을 규제항으로 사용함으로써 0에 가까운 계수를 0으로 만들어 **영향을 거의 미치지 않는 단어들을 제외**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.718\n",
      "Test set score: 0.643\n",
      "Used features count: 240 out of 2023\n"
     ]
    }
   ],
   "source": [
    "#lasso를 쓰면?\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "print('Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1])\n",
    "# 현재까지 방법 중에 train score, test score 모두 가장 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) LSA(Latent Semantic Analysis, 잠재의미분석)\n",
    "* a technique in natural language processing, in particular distributional semantics, of *analyzing relationships between a set of documents and the terms they contain* by **producing a set of concepts related to the documents and terms**. LSA assumes that **words that are close in meaning will occur in similar pieces of text** (the distributional hypothesis, 분배/분해 가설)\n",
    "\n",
    "* **SVD**(Singular Vector Decomposition), 특이값 분해 : 주어진 dtm(document term matrix, A)을 A=U\\*Σ\\*V^T의 형태로 분해\n",
    "* **Truncated SVD**, 잠재의미분석 : Σ 행렬의 대각원소(특이값) 가운데 잠재의미군 비중에 큰 상위 t개만 골라내어 A'=Ut(m, t)\\*Σ(t, t)\\*VtT(t, n)의 형태로 분해되어 A에 근사한 A'값을 구할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01102934 0.01405529 0.01144551 0.0110093  0.00918016 0.00876149\n",
      " 0.00836851 0.00795922 0.00777003 0.00737423 0.00707199 0.00665546\n",
      " 0.00659729 0.00616382 0.00588976 0.00563969 0.00546929 0.00543044\n",
      " 0.00524396 0.00523751 0.0051354  0.00507564 0.00494917 0.00478661\n",
      " 0.00466253 0.0046021  0.00455272 0.00452943 0.00432636 0.0043043\n",
      " 0.00425346 0.00416261 0.00410043 0.00401296 0.00399825 0.00396182\n",
      " 0.00392779 0.00385998 0.00373325 0.00369469 0.00365484 0.00363113\n",
      " 0.00357832 0.00354544 0.00349848 0.00346928 0.00337552 0.00334918\n",
      " 0.00332458 0.00330956 0.00323571 0.00321667 0.00315217 0.00314053\n",
      " 0.00309441 0.00307477 0.0030649  0.00301359 0.00300256 0.00296081\n",
      " 0.00293836 0.00291433 0.00288938 0.00288701 0.00286437 0.00281526\n",
      " 0.00280011 0.00276482 0.00274032 0.00271676 0.00269105 0.00266254\n",
      " 0.00264105 0.00262961 0.00260318 0.00258836 0.00257263 0.0025549\n",
      " 0.00253862 0.00252722 0.00251281 0.00248844 0.00248194 0.00245121\n",
      " 0.00244755 0.00241116 0.00239864 0.0023803  0.00236743 0.00235925\n",
      " 0.00232777 0.00231998 0.00228583 0.00225879 0.00224278 0.00222963\n",
      " 0.00222807 0.00219394 0.00218403 0.00217777 0.00216885 0.00213963\n",
      " 0.00213221 0.00211726 0.0021082  0.00208491 0.00207873 0.00206984\n",
      " 0.0020442  0.00203715 0.00203109 0.00202247 0.00200684 0.00199728\n",
      " 0.00198139 0.00197578 0.00196858 0.0019567  0.00195046 0.00193928\n",
      " 0.00192188 0.00191527 0.00190398 0.00190288 0.00189315 0.00188382\n",
      " 0.00186635 0.00185401 0.00184764 0.00184161 0.0018402  0.00182065\n",
      " 0.001813   0.00179631 0.00179194 0.00178155 0.00177619 0.00177247\n",
      " 0.00176391 0.00174575 0.00174084 0.00173493 0.00172713 0.00172038\n",
      " 0.00171324 0.00169736 0.00169107 0.00168815 0.00167718 0.00166958\n",
      " 0.0016606  0.00165005 0.00164831 0.00163445 0.00162676 0.00162542\n",
      " 0.00161713 0.00161272 0.00159771 0.00159238 0.00159037 0.00158957\n",
      " 0.00156833 0.00156387 0.00155943 0.00155314 0.00154517 0.00154178\n",
      " 0.00153878 0.00153156 0.00152027 0.00151681 0.00150908 0.00150907\n",
      " 0.00150429 0.00148962 0.00148561 0.00147865 0.00147801 0.00146682\n",
      " 0.00146001 0.00145723 0.00144468 0.00143961 0.00143002 0.00142921\n",
      " 0.0014208  0.00141638 0.00141579 0.00140818 0.0014034  0.00139324\n",
      " 0.00139056 0.00138567 0.00137493 0.00137155 0.00136727 0.00135985\n",
      " 0.00135444 0.00134977 0.00134562 0.00133558 0.00133122 0.00132535\n",
      " 0.00132194 0.00131758 0.00131066 0.00130911 0.00130505 0.00129728\n",
      " 0.00129571 0.00128405 0.00127616 0.00127324 0.00126559 0.00125941\n",
      " 0.00125722 0.00125095 0.00124375 0.00124088 0.00123686 0.00123166\n",
      " 0.00122136 0.00121416 0.00120729 0.00119822 0.00119425 0.0011902\n",
      " 0.00118219 0.00117517 0.00117452 0.0011669  0.00115835 0.00114922\n",
      " 0.00114639 0.00113962 0.00113862 0.00113157 0.00112449]\n",
      "0.6274704549280449\n",
      "[7.18722998 4.37716265 3.87707769 3.80401495 3.46987465 3.38992696\n",
      " 3.31319188 3.23081401 3.19295868 3.11176267 3.0479269  2.97464527\n",
      " 2.94181282 2.84376785 2.7792728  2.72052017 2.67818072 2.66871722\n",
      " 2.62671166 2.6211839  2.59772293 2.58190277 2.54773577 2.50549056\n",
      " 2.47514125 2.46249764 2.44458218 2.44081919 2.38195771 2.37595715\n",
      " 2.36213857 2.33646299 2.31897222 2.29462272 2.28988032 2.27951064\n",
      " 2.2696032  2.25224959 2.21275983 2.20157946 2.18941753 2.18229454\n",
      " 2.16700863 2.15629757 2.14384191 2.13417342 2.10461423 2.09580568\n",
      " 2.08809633 2.08457671 2.06118326 2.05524985 2.03983521 2.02947381\n",
      " 2.0156339  2.00808902 2.00484508 1.98892489 1.9848698  1.97080544\n",
      " 1.96433732 1.95685115 1.94851579 1.94618356 1.93878407 1.92354149\n",
      " 1.91631125 1.90417728 1.8957369  1.88786307 1.8786183  1.86911358\n",
      " 1.86110158 1.85717919 1.84914318 1.84466386 1.83680751 1.83047136\n",
      " 1.8257132  1.82052779 1.81602147 1.80661829 1.80431053 1.79331989\n",
      " 1.79183982 1.77843174 1.77363887 1.76688172 1.76225481 1.75901716\n",
      " 1.7472136  1.74547341 1.73138953 1.72112568 1.71500666 1.71000327\n",
      " 1.70948057 1.69627556 1.69249592 1.69011496 1.68727252 1.67602962\n",
      " 1.67226219 1.66647038 1.66276613 1.65396201 1.65116958 1.64756305\n",
      " 1.63885047 1.6351727  1.63216299 1.62859852 1.62272231 1.6199386\n",
      " 1.61197651 1.60973638 1.60686067 1.6019874  1.59937235 1.59485625\n",
      " 1.58767203 1.58485923 1.58104529 1.57976164 1.57568875 1.57192692\n",
      " 1.56637507 1.55945183 1.55681473 1.55449401 1.55349754 1.54521608\n",
      " 1.54228311 1.53494218 1.53323466 1.52873209 1.52685008 1.52467317\n",
      " 1.52095301 1.51360868 1.51136655 1.50844406 1.50501843 1.50295063\n",
      " 1.4990343  1.49203042 1.48921439 1.48844592 1.48323386 1.47971939\n",
      " 1.47588973 1.47125412 1.47030967 1.46441287 1.46089164 1.4600098\n",
      " 1.45645421 1.45430045 1.44757356 1.4451948  1.44418574 1.44381833\n",
      " 1.43474477 1.43241517 1.43075667 1.42734688 1.4239681  1.42213184\n",
      " 1.42056782 1.41722678 1.4129636  1.41085354 1.40692287 1.40682537\n",
      " 1.40490821 1.39769447 1.39580527 1.39275219 1.3922484  1.38695654\n",
      " 1.38382998 1.38275183 1.37645068 1.37404564 1.36964869 1.36905779\n",
      " 1.36514341 1.36291003 1.36262579 1.35901456 1.35666126 1.35220907\n",
      " 1.35071654 1.34873489 1.34301621 1.34134439 1.33943739 1.33542613\n",
      " 1.33276808 1.33056349 1.3284238  1.32349714 1.32147413 1.31838175\n",
      " 1.31677435 1.31457724 1.31126584 1.31041624 1.30838878 1.30434815\n",
      " 1.30356031 1.29770436 1.29424264 1.29220091 1.28853219 1.28520775\n",
      " 1.2841347  1.28089417 1.27725376 1.27569374 1.27362989 1.27093976\n",
      " 1.26565419 1.26203966 1.25829658 1.25355624 1.25168127 1.24946418\n",
      " 1.24542796 1.24144044 1.24113263 1.23706028 1.2325742  1.22773662\n",
      " 1.22629484 1.22251701 1.22209418 1.21818685 1.21495199]\n",
      "(239, 2023)\n"
     ]
    }
   ],
   "source": [
    "#lsa를 쓰면?\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=239, n_iter=7, random_state=42) #압축할 component의 수 지정\n",
    "svd.fit(X_train_tfidf)\n",
    "print(svd.explained_variance_ratio_)  #계산된 각 component가 설명하는 분산의 비율\n",
    "print(svd.explained_variance_ratio_.sum())  #선택된 component들이 설명하는 분산의 합 -> 선택한 component의 수에 따라 달라짐\n",
    "print(svd.singular_values_)   #특이값\n",
    "print(svd.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.771\n",
      "Test set score: 0.654\n"
     ]
    }
   ],
   "source": [
    "## 특이값 분해(SVD, singular vector decomposition)로 차원 축소\n",
    "X_train_svd = svd.transform(X_train_tfidf)\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n",
    "#선택된 component를 이용하여 2,000개의 feature로부터 feature extract (차원축소=dimension reduce)\n",
    "\n",
    "## 학습 및 성능체크\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "SVD_clf = LogisticRegression()\n",
    "SVD_clf.fit(X_train_svd, y_train)\n",
    "print('Train set score: {:.3f}'.format(SVD_clf.score(X_train_svd, y_train)))\n",
    "print('Test set score: {:.3f}'.format(SVD_clf.score(X_test_svd, y_test)))\n",
    "# 마찬가지로 train, test score 모두 lasso 회귀 다음으로 가장 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Naïve Bayes(NB)\n",
    "\n",
    "* Wikipedia: a popular (baseline) method for text categorization, the problem of judging documents as belonging to one category or the other (such as spam or legitimate, sports or politics, etc.) with word frequencies (count vector) as the features.\n",
    "\n",
    "* (x1, …, xn) 의 단어집합으로 이루어진 문서가 분류 Ck에 속할 확률\n",
    "* 예제 <http://bcho.tistory.com/m/1010>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Okyoung\\Downloads\\ANACONDA\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set dimension: (1370, 1584)\n",
      "Test set dimension: (457, 1584)\n",
      "Train set score: 0.801\n",
      "Test set score: 0.685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "## 명사, 동사, 형용사만 tokenize\n",
    "cv = CountVectorizer(tokenizer=twit_tokenizer2, min_df=2).fit(X_train) #tfidf와 동일하게 max_feature를 제한하여 학습\n",
    "X_train_cv = cv.transform(X_train) # train set을 변환\n",
    "print('Train set dimension:', X_train_cv.shape) # 36310 대신 2000이 된 것을 확인\n",
    "X_test_cv = cv.transform(X_test) # test set을 변환\n",
    "print('Test set dimension:', X_test_cv.shape)\n",
    "\n",
    "## 학습 및 성능체크\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB_clf = MultinomialNB()\n",
    "NB_clf.fit(X_train_cv, y_train)\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train)))\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test)))\n",
    "# train score는 명사, 동사, 형용사를 사용한 경우보다 다소 떨어짐\n",
    "# test score는 사용한 방법들 중 가장 높게 나옴!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사용한 방법들의 train, test set score 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>명사</td>\n",
       "      <td>0.8364</td>\n",
       "      <td>0.6717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>형태소</td>\n",
       "      <td>0.8963</td>\n",
       "      <td>0.6498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>명동형</td>\n",
       "      <td>0.8715</td>\n",
       "      <td>0.6849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>형태소+품사</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>0.6739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>릿지</td>\n",
       "      <td>0.9440</td>\n",
       "      <td>0.6760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>라쏘</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>0.6430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSA</td>\n",
       "      <td>0.7710</td>\n",
       "      <td>0.6540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>나이브 베이즈</td>\n",
       "      <td>0.8010</td>\n",
       "      <td>0.6850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method   train    test\n",
       "0       명사  0.8364  0.6717\n",
       "1      형태소  0.8963  0.6498\n",
       "2      명동형  0.8715  0.6849\n",
       "3   형태소+품사  0.8927  0.6739\n",
       "4       릿지  0.9440  0.6760\n",
       "5       라쏘  0.7180  0.6430\n",
       "6      LSA  0.7710  0.6540\n",
       "7  나이브 베이즈  0.8010  0.6850"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "scores = pd.read_csv('C:/Users/Okyoung/Desktop/Business Analytics_캡스톤디자인/BusinessAnalytics/HW/compare_score.csv')\n",
    "\n",
    "scores   #나이브 베이즈(NB)가 가장 좋은 test score를 보유"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
